{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf0bcc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load packages\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, matthews_corrcoef\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #i hate the subsetting failure messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6991b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "#load data\n",
    "#faster than reading one by one actually\n",
    "file_paths = [\n",
    "    \"/Users/Minett/Downloads/animalshelterdata_fy2425.csv\",\n",
    "    \"/Users/Minett/Downloads/animalshelterdata_fy2324.csv\",\n",
    "    \"/Users/Minett/Downloads/animalshelterdata_fy2223.csv\",\n",
    "    \"/Users/Minett/Downloads/animalshelterdata_fy2122.csv\",\n",
    "    \"/Users/Minett/Downloads/animalshelterdata_fy2021.csv\",\n",
    "    \"/Users/Minett/Downloads/animalshelterdata_fy1920.csv\",\n",
    "    \"/Users/Minett/Downloads/animalshelterdata_fy1819.csv\"\n",
    "]\n",
    "dataframes = [pd.read_csv(file) for file in file_paths]\n",
    "shelter_data = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be556e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleaning\n",
    "#remove not valid outcomes\n",
    "valid_outcomes = ['ADOPTION', 'FOSTER', 'DIED', \n",
    "                  'EUTH', 'RESCUE']\n",
    "shelter_data_filtered = shelter_data[shelter_data['OutcomeType'].isin(valid_outcomes)]\n",
    "invalid_combinations = [('FOSTER', 'ADOPTION'), ('FOSTER', 'RESCUE'), ('FOSTER', 'FOSTER')]\n",
    "for intake, outcome in invalid_combinations:\n",
    "    shelter_data_filtered = shelter_data_filtered[~((shelter_data_filtered['IntakeType'] == intake) &(shelter_data_filtered['OutcomeType'] == outcome))]\n",
    "shelter_data_filtered_no_dupes = shelter_data_filtered.drop_duplicates(subset='AnimalID', keep='first').copy()\n",
    "\n",
    "# date columns into datetime for splitting later\n",
    "shelter_data_filtered_no_dupes['IntakeDate'] = pd.to_datetime(shelter_data_filtered_no_dupes['IntakeDate'])\n",
    "shelter_data_filtered_no_dupes['OutcomeDate'] = pd.to_datetime(shelter_data_filtered_no_dupes['OutcomeDate'])\n",
    "# new year,month,day columns from  previous datatime\n",
    "for prefix, col in [('Intake', 'IntakeDate'), ('Outcome', 'OutcomeDate')]:\n",
    "    shelter_data_filtered_no_dupes[f'{prefix}Year'] = \n",
    "    shelter_data_filtered_no_dupes[col].dt.year\n",
    "    shelter_data_filtered_no_dupes[f'{prefix}Month'] = \n",
    "    shelter_data_filtered_no_dupes[col].dt.month\n",
    "    shelter_data_filtered_no_dupes[f'{prefix}Day'] = \n",
    "    shelter_data_filtered_no_dupes[col].dt.day\n",
    "\n",
    "# new variable for time spent in shelter which is LOS\n",
    "shelter_data_filtered_no_dupes['Time_Spent_In_Shelter_Days'] = (shelter_data_filtered_no_dupes['OutcomeDate'] - shelter_data_filtered_no_dupes['IntakeDate']).dt.days\n",
    "\n",
    "#convert age to numeric and strip out the words in the column\n",
    "shelter_data_filtered_no_dupes['Age_Numeric'] = pd.to_numeric(\n",
    "    shelter_data_filtered_no_dupes['Age'].str.extract('(\\d+)')[0], \n",
    "    errors='coerce')\n",
    "\n",
    "\n",
    "# features re-encoded or dropped\n",
    "columns_to_drop = [\n",
    "    'LastUpdate', 'IntakeDate', 'OutcomeDate', 'Age', 'Crossing', 'OutcomeSubtype', 'OutcomeCondition', 'DOB'\n",
    "]\n",
    "shelter_data_filtered_no_dupes.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "numerical_cols = ['Age_Numeric', 'Time_Spent_In_Shelter_Days', 'IntakeYear', 'IntakeMonth', 'IntakeDay', 'OutcomeYear', 'OutcomeMonth', 'OutcomeDay']\n",
    "categorical_cols = ['AnimalType', 'PrimaryColor', 'SecondaryColor', 'PrimaryBreed', 'Sex', 'IntakeCondition', 'IntakeType', 'IntakeSubtype', 'IntakeReason', 'Jurisdiction']\n",
    "\n",
    "# Multiclass setup\n",
    "#we also drop more variables we do not need\n",
    "#in the future, you coudl do sentiment analysis on the names though\n",
    "#we didnt learn that though lol\n",
    "X = shelter_data_filtered_no_dupes.drop(['AnimalID', 'AnimalName', 'OutcomeType'], axis=1)\n",
    "y = shelter_data_filtered_no_dupes['OutcomeType']\n",
    "# general train-test split setup\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=245)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bae5d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multinomial random forest model run and print metrics\n",
    "#HERE's the modelling\n",
    "\n",
    "# Preprocessor setup\n",
    "#some feature engineering here that worked out for me\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('poly', PolynomialFeatures(degree=2, interaction_only=True,\n",
    "                                        include_bias=False))\n",
    "        ]), numerical_cols),\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore', \n",
    "                                     drop='first', sparse_output=False))\n",
    "        ]), categorical_cols)])\n",
    "\n",
    "# Random Forest model init\n",
    "rf_model = RandomForestClassifier(random_state=245, class_weight='balanced') #balanced for OUR UNBALANCED classes\n",
    "\n",
    "# Add the SMOTE to pipeline\n",
    "pipeline_rf = ImbPipeline(steps=[('preprocessor', preprocessor), \n",
    "                                 ('smote', SMOTE(random_state=245)),  \n",
    "                                 ('model', rf_model)])\n",
    "\n",
    "#hyperparameter grid\n",
    "#we use towards data science article hyper params \n",
    "#shotgun technqiue!\n",
    "random_grid = {\n",
    "    'model__n_estimators': [50, 100, 150],\n",
    "    'model__max_features': ['auto', 'sqrt'],\n",
    "    'model__max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 4],\n",
    "    'model__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "#set randomsearch method to fit \n",
    "rf_random = RandomizedSearchCV(estimator=pipeline_rf, param_distributions=random_grid, \n",
    "                               cv=StratifiedKFold(n_splits=5),\n",
    "                               n_iter=100, random_state=245, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# fit + predict probabiltiies\n",
    "rf_random.fit(X_train, y_train)\n",
    "best_model = rf_random.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)\n",
    "\n",
    "# Multiclass metrics\n",
    "print(\"\\nOptimized Random Forest Model Performance:\")\n",
    "print(\"Best Parameters:\", rf_random.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# ROC-AUC and MCC for multiclass\n",
    "#yes it does work for multiclass\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_proba, multi_class=\"ovr\"))\n",
    "#we do have to make convert\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", matthews_corrcoef(y_test, y_pred))  #this should work normally in a multinomial setting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5dc752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary rf model\n",
    "shelter_data_filtered_no_dupes['OutcomeType_Binary'] = shelter_data_filtered_no_dupes['OutcomeType'].replace(\n",
    "    {'ADOPTION': 'POSITIVE_OUTCOME', 'FOSTER': 'POSITIVE_OUTCOME', 'RESCUE': 'POSITIVE_OUTCOME',\n",
    "     'EUTH': 'NEGATIVE_OUTCOME', 'DIED': 'NEGATIVE_OUTCOME'}\n",
    ")\n",
    "\n",
    "#set x binary featurs\n",
    "X_bin = shelter_data_filtered_no_dupes.drop(['AnimalID', 'AnimalName', 'OutcomeType', 'OutcomeType_Binary'], axis=1)\n",
    "#set y binary outcomes\n",
    "y_bin = shelter_data_filtered_no_dupes['OutcomeType_Binary']\n",
    "\n",
    "# same old train test split\n",
    "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(X_bin, y_bin, test_size=0.2, random_state=245)\n",
    "\n",
    "# binary pipeline\n",
    "pipeline_rf_bin = ImbPipeline(steps=[('preprocessor', preprocessor), \n",
    "                                     ('smote', SMOTE(random_state=245)),  \n",
    "                                     ('model', rf_model)])\n",
    "\n",
    "#binary grid search\n",
    "rf_random_bin = RandomizedSearchCV(estimator=pipeline_rf_bin, param_distributions=random_grid, \n",
    "                                   n_iter=100, cv=StratifiedKFold(n_splits=5), \n",
    "                                   verbose=2, random_state=245, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# binary model fit start\n",
    "rf_random_bin.fit(X_train_bin, y_train_bin)\n",
    "#best binary model\n",
    "best_model_bin = rf_random_bin.best_estimator_\n",
    "\n",
    "# binary prediction\n",
    "y_pred_bin = best_model_bin.predict(X_test_bin)\n",
    "y_pred_proba_bin = best_model_bin.predict_proba(X_test_bin)[:, 1] #grab probabilities to use later\n",
    "\n",
    "# Binary metrics\n",
    "print(\"\\nOptimized Binary Random Forest Model Performance:\")\n",
    "print(\"Best Parameters:\", rf_random_bin.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_bin, y_pred_bin))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_bin, y_pred_bin))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_bin, y_pred_bin))\n",
    "\n",
    "# ROC-AUC and MCC for binary classification\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test_bin, y_pred_proba_bin))\n",
    "print(\"Matthews Correlation Coefficient (MCC):\", matthews_corrcoef(y_test_bin, y_pred_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ce486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump model\n",
    "joblib.dump(best_model, 'final_best_random_forest_multiclass_model.joblib')\n",
    "joblib.dump(best_model_bin, 'final_best_random_forest_binary_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
